\documentclass{homework}
\usepackage{homework}

\title{COC473 - Lista 3}
\author{Pedro Maciel Xavier}
\register{116023847}
\date{25 de setembro de 2020}

\begin{document}
	
	\maketitle
	
	\quest%%1
	
	Começamos com o conjunto de pontos descrito abaixo:
	
	\begin{fig}
		\begin{tabular}{|c|c|c|}
			\hline
			$i$ & $x_i$ & $y_i$\\
			\hline
			1 & 1 & 1\\
			2 & 2 & 2\\
			3 & 3 & 9\\
			\hline
		\end{tabular}
	\end{fig}

	Dados $n = 3$ pontos, precisaremos de um polinômio interpolador de grau $n - 1 = 2$. Assim, supomos $p(x) = a x^2 + b x + c$. Queremos, portanto, satisfazer
		$$ \forall i ~ p(x_i) = a x_i^2 + b x_i + c = y_i  $$
	que podemos reescrever na forma matricial
		$$ \left[\begin{array}{@{}ccc@{}} %% A
		1 & x_1 & x_1^2\\
		1 & x_2 & x_2^2\\
		1 & x_3 & x_3^2\\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		c\\
		b\\
		a 
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		y_1\\
		y_2\\
		y_3 
		\end{array}\right]
		$$
	substituindo:
		$$ \left[\begin{array}{@{}ccc@{}} %% A
		1 & 1 & 1\\
		1 & 2 & 4\\
		1 & 3 & 9\\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		c\\
		b\\
		a 
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		1\\
		2\\
		9
		\end{array}\right]
		$$
	Resolvendo o sistema linear, encontramos
		\begin{align*}
			a &= 3\\
			b &= -8\\
			c &= 6
		\end{align*}
	como solução. Temos então o polinômio interpolador $p_\text{I}(x) = 3 x^2 - 8 x + 6$.

	\quest%%2
	
	Acrescentando o ponto $(4, 20)$, temos o seguinte conjunto de pontos:
	
	\begin{fig}
		\begin{tabular}{|c|c|c|}
			\hline
			$i$ & $x_i$ & $y_i$\\
			\hline
			1 & 1 & 1\\
			2 & 2 & 2\\
			3 & 3 & 9\\
			4 & 4 & 20\\
			\hline
		\end{tabular}
	\end{fig}

	Seguindo procedimento análogo ao anterior, só que desta vez com um polinômio de grau $n - 1 = 4$, que chamaremos $p(x) = a_3 x^3 a_2 x^2 + a_1 x + a_0$, montamos o sistema
		$$ \left[\begin{array}{@{}cccc@{}} %% A
		1 & x_1 & x_1^2 & x_1^3\\
		1 & x_2 & x_2^2 & x_2^3\\
		1 & x_3 & x_3^2 & x_3^3\\
		1 & x_4 & x_4^2 & x_4^3
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		a_0\\
		a_1\\
		a_2\\
		a_3 
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		y_1\\
		y_2\\
		y_3\\
		y_4 
		\end{array}\right]
		$$
	substituindo:
		$$ \left[\begin{array}{@{}cccc@{}} %% A
		1 & 1 & 1 & 1\\
		1 & 2 & 4 & 8\\
		1 & 3 & 9 & 27\\
		1 & 4 & 16 & 64
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		a_0\\
		a_1\\
		a_2\\
		a_3
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		1\\
		2\\
		9\\
		20
		\end{array}\right]
		$$
	A solução encontrada nos diz que
		$$
		\left[\begin{array}{@{}c@{}} %% x
		a_0\\
		a_1\\
		a_2\\
		a_3
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		8\\
		-\frac{35}{3}\\
		5\\
		-\frac{1}{3}
		\end{array}\right]
		$$
	Por fim, temos o polinômio interpolador $p_\text{II}(x) = -\frac{1}{3} x^3 + 5 x^2 -\frac{35}{3} x + 8$.
	
	\quest%%3
	
	Seja $g(x) = b_1 x^{b_2}$. Vamos definir $\varPsi(x) = \log g(x) = \log b_1 + b_2 \log x$. Além disso, vamos escrever $\hat{x} = \log x$ e $\hat{b}_1 = \log b_1$. Assim,  $\varPsi(x) = \hat{b}_1 + b_2 \hat{x}$. Por se tratar de um ajuste, não estamos interessados em passar pelos pontos $(x_i, y_i)$ com exatidão, mas sim reduzir a soma das distâncias de cada um destes pontos para a curva ajustada.\par
	
	Comecemos com a definição do erro quadrático médio:
		\begin{align*}
		E[\varPsi(x)]^2 &= \sum_{i = 1}^{n} (\varPsi(x_i) - y_i)^2\\
						&= \sum_{i = 1}^{n} (\hat{b}_1 + b_2 \hat{x}_i - y_i)^2
		\end{align*}
	Em seguida, para minimizar o erro, calculamos o par de derivadas em relação a $\hat{b}_1 $ e $b_2$
		\begin{align*}
		\frac{\partial E[\varPsi(x)]^2}{\partial \hat{b}_1} &= 2 \sum_{i = 1}^{n} (\hat{b}_1 + b_2 \hat{x}_i - y_i)\\
		\frac{\partial E[\varPsi(x)]^2}{\partial b_2} &= 2 \sum_{i = 1}^{n} (\hat{b}_1 + b_2 \hat{x}_i - y_i) \hat{x}_i\\
		\end{align*}%%
	e igualamos ambas a $0$, a fim de obter os pontos de mínimo global da função quadrática.
		\begin{align*}
		\sum_{i = 1}^{n}& (\hat{b}_1 + b_2 \hat{x}_i - y_i) = 0\\
		\sum_{i = 1}^{n}& (\hat{b}_1 + b_2 \hat{x}_i - y_i) \hat{x}_i = 0\\
		\end{align*}%%
	Escrevendo na forma matricial
		$$ \left[\begin{array}{@{}cc@{}} %% A
		n & \sum_{i = 1}^{n} \hat{x}_i\\
		\sum_{i = 1}^{n} \hat{x}_i & \sum_{i = 1}^{n} \hat{x}_i^2 \\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		\hat{b}_1\\
		b_2
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		\sum_{i = 1}^{n} y_i\\
		\sum_{i = 1}^{n} y_i \hat{x}_i
		\end{array}\right]
		$$
	e substituindo os valores
		$$ \left[\begin{array}{@{}cc@{}} %% A
		4 & 3.178\\
		3.178 & 3.609 \\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		\hat{b}_1\\
		b_2
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		5.886\\
		7.047
		\end{array}\right]
		$$
	e, por fim, resolvendo temos:
		$$
		\left[\begin{array}{@{}c@{}} %% x
			\hat{b}_1\\
			b_2
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
			-0.265\\
			2.186
		\end{array}\right]
		$$
	desfazendo a substituição, concluímos que $b_1 = e^{\hat{b}_1} = 0.766$. Obtivemos assim, um ajuste através da função $g_\text{III}(x) = 0.766 x^{2.186}$.
	
	
	\quest%%4
	
	Para o cálculo do polinômio interpolador de Lagrange, analisamos primeiro o produto $\varPhi_i(x)$ correspondente a cada ponto $x_i$.
		\begin{align*}
		\varPhi_1(x) &= \frac{(x - 2) (x - 3) (x - 4)}{(1 - 2) (1 - 3) (1 - 4)}\\
		\varPhi_2(x) &= \frac{(x - 1) (x - 3) (x - 4)}{(2 - 1) (2 - 3) (2 - 4)}\\
		\varPhi_3(x) &= \frac{(x - 1) (x - 2) (x - 4)}{(3 - 1) (3 - 2) (3 - 4)}\\
		\varPhi_4(x) &= \frac{(x - 1) (x - 2) (x - 3)}{(4 - 1) (4 - 2) (4 - 3)}
		\end{align*}%%
	Calculando o somatório das expressões, ponderados por cada $y_i$, chegamos a
		$$p_\text{IV}(x) = \sum_{i=1}^{n} y_i \varPhi_i(x) = -\frac{1}{3} x^3 + 5 x^2  -\frac{35}{3} x + 8$$
	
	\quest%%5
	
	Partindo de um polinômio na forma $f(x) = a x^2 + b x + c$, vamos construir um ajuste da maneira semelhante àquela feita anteriormente, no item 3). Partindo das derivadas parciais em relação aos coeficientes temos
		\begin{align*}
		\frac{\partial E[f(x)]^2}{\partial a} &= 2 \sum_{i = 1}^{n} (a x_i^2 + b x_i + c - y_i) x_i^2 = 0\\
		\frac{\partial E[f(x)]^2}{\partial b} &= 2 \sum_{i = 1}^{n} (a x_i^2 + b x_i + c - y_i) x_i = 0\\
		\frac{\partial E[f(x)]^2}{\partial c} &= 2 \sum_{i = 1}^{n} (a x_i^2 + b x_i + c - y_i) = 0\\
		\end{align*}%%
	de onde segue, na forma matricial, que
		$$ \left[\begin{array}{@{}cccc@{}} %% A
		n                      & \sum_{i = 1}^{n} x_i   & \sum_{i = 1}^{n} x_i^2\\
		\sum_{i = 1}^{n} x_i   & \sum_{i = 1}^{n} x_i^2 & \sum_{i = 1}^{n} x_i^3\\
		\sum_{i = 1}^{n} x_i^2 & \sum_{i = 1}^{n} x_i^3 & \sum_{i = 1}^{n} x_i^4
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		c\\
		b\\
		a
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		\sum_{i = 1}^{n} y_i\\
		\sum_{i = 1}^{n} y_i x_i\\
		\sum_{i = 1}^{n} y_i x_i^2
		\end{array}\right]
		$$
	substituindo, obtemos
		$$ \left[\begin{array}{@{}cccc@{}} %% A
		4  & 10  & 30\\
		10 & 30  & 100\\
		30 & 100 & 354
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		c\\
		b\\
		a
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		32\\
		112\\
		410
		\end{array}\right]
		$$
	cuja solução é
		$$
		\left[\begin{array}{@{}c@{}} %% x
		c\\
		b\\
		a
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		4.5\\
		-6.1\\
		2.5
		\end{array}\right]
		$$
	Assim, calculamos os coeficientes do polinômio $p_\text{V}(x) = 2.5 x^2 - 6.1 x + 4.5$.
	
	\quest%%6
	
	Organizados na tabela seguinte estão as funções calculadas nas questões anteriores assim como o valor das mesmas para $x = 3.5$.
	
	\begin{fig}
		\begin{tabular}{|l|c|}
			\hline
			$f(x)$ & $f(3.5)$\\
			\hline
			$p_\text{I}(x) = 3 x^2 - 8 x + 6$ & $14.750$ \\
			$p_\text{II}(x) = -\frac{1}{3} x^3 + 5 x^2 -\frac{35}{3} x + 8$ & $14.125$ \\
			$g_\text{III}(x) = 0.766 x^{2.186}$ & $11.845$ \\
			$p_\text{IV}(x) = -\frac{1}{3} x^3 + 5 x^2  -\frac{35}{3} x + 8$ & $14.125$\\
			$p_\text{V}(x) = 2.5 x^2 - 6.1 x + 4.5$ & $13.775$\\
			\hline
		\end{tabular}
	\end{fig}

	\quest%%7
	
	Temos agora novos dados, organizados na tabela abaixo:
	
	\begin{fig}
		\begin{tabular}{|c|c|c|}
			\hline
			$i$ & $x_i$ & $y_i$\\
			\hline
			1 & 1 & 1\\
			2 & 2 & 2.5\\
			3 & 3 & 3.5\\
			4 & 4 & 4.3\\
			\hline
		\end{tabular}
	\end{fig}
	
	Seja $g(x) = a \log x + \frac{b}{x^2 + 1}$. Comecemos com algumas substituições para auxiliar a notação:
		\begin{align*}
			\hat{x} & = \log x\\
			\check{x} &= \frac{1}{x^2 + 1}
		\end{align*}
	Reescrevemos $g(x) = a \hat{x} + b \check{x}$. Seguimos com o procedimento usual de ajuste por mínimos quadrados. Partimos das derivadas do erro quadrático médio em relação aos coeficientes $a$ e $b$:
		\begin{align*}
		\frac{\partial E[g(x)]^2}{\partial a} &= 2 \sum_{i = 1}^{n} (a \hat{x} + b \check{x} - y_i) \hat{x} = 0\\
		\frac{\partial E[g(x)]^2}{\partial b} &= 2 \sum_{i = 1}^{n} (a \hat{x} + b \check{x} - y_i) \check{x} = 0\\
		\end{align*}%%
	Passando para a forma de matriz
		$$ \left[\begin{array}{@{}cc@{}} %% A
		\sum_{i = 1}^{n} \hat{x}^2 & \sum_{i = 1}^{n} \hat{x} \check{x} \\
		\sum_{i = 1}^{n} \hat{x} \check{x} & \sum_{i = 1}^{n} \check{x}^2 \\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		a\\
		b
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		\sum_{i = 1}^{n} y_i \hat{x} \\
		\sum_{i = 1}^{n} y_i \check{x}
		\end{array}\right]
		$$	
	e substituindo pelos valores da tabela:
		$$ \left[\begin{array}{@{}cc@{}} %% A
		3.609 & 0.330 \\
		0.330 & 3.303 \\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		a\\
		b
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		11.539 \\
		1.602
		\end{array}\right]
		$$
	o que nos dá
		$$\left[\begin{array}{@{}c@{}} %% x
		a\\
		b
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		3.013 \\
		2.004
		\end{array}\right]
		$$
	e assim construímos $g(x) = 3.013 \log x + \frac{2.004}{x^2 + 1}$.
	
	\quest
	
	Dados dois vetores $\vec{x}, \vec{y} \in \mathbb{R}^n$ contendo em cada $i$-ésima coordenada uma observação de um dado fenômeno, queremos ajustar a reta $y = f(x) = a x + b$ que melhor aproxima os valores quando $x = \vec{x}_i$ e $y = \vec{y}_i$. Como de costume, calculamos o erro quadrático médio proporcionado por $f(x)$:
		\begin{align*}
			E[f(x)]^2 &= \sum_{i=1}^{n} (f(\vec{x}_i) - \vec{y}_i)^2 = \sum_{i=1}^{n} (a \vec{x}_i + b  - \vec{y}_i)^2
		\end{align*}
	Para minimizar o erro, encontramos primeiro as derivadas parciais com respeito aos parâmetros $a$ e $b$ e dizemos que esta se anula, pois assim obtemos seu ponto crítico de mínimo.
		\begin{align*}
			\frac{\partial E[f(x)]^2}{\partial a} &= 2 \sum_{i=1}^{n} (a \vec{x}_i + b  - \vec{y}_i) x_i = 0\\
			\frac{\partial E[f(x)]^2}{\partial b} &= 2 \sum_{i=1}^{n} (a \vec{x}_i + b  - \vec{y}_i) = 0
		\end{align*}
	Isso nos permite escrever
		\begin{align*}
			a \sum_{i=1}^{n} \vec{x}_i^2 + b \sum_{i=1}^{n} x_i &= \sum_{i=1}^{n} \vec{x}_i \vec{y}_i\\
			a \sum_{i=1}^{n} \vec{x}_i + b n  &= \sum_{i=1}^{n} \vec{y}_i
		\end{align*}
	que na forma matricial nos dá
		$$ \left[\begin{array}{@{}cc@{}} %% A
		n & \sum_{i=1}^{n} \vec{x}_i \\
		\sum_{i=1}^{n} \vec{x}_i & \vec{x}^\T\vec{x} \\
		\end{array}\right]%%
		%%
		\left[\begin{array}{@{}c@{}} %% x
		b\\
		a
		\end{array}\right]
		=		
		\left[\begin{array}{@{}c@{}} %% b
		\sum_{i=1}^{n} \vec{y}_i\\
		\vec{x}^\T\vec{y}
		\end{array}\right]
		$$
	Por fim, a resolução do sistema nos entrega o resultado. Como a matriz é simétrica, podemos utilizar a decomposição de Cholesky para resolver o sistema. 
	
	\begin{fortran}[Mínimos quadrados]
	function least_squares(x, y, s, n) result (ok)
	!	Dados x(n), y(n), n. O Resultado é armazenado em s(2) = [b, a]
		implicit none
		integer :: n
		
		logical :: ok
		
		double precision :: A(2,2), b(2), s(2), r(2), x(n), y(n)
		
		A(1, 1) = n
		A(1, 2) = SUM(x)
		A(2, 1) = SUM(x)
		A(2, 2) = DOT_PRODUCT(x, x)
		
		b(1) = SUM(y)
		b(2) = DOT_PRODUCT(x, y)
		
		ok = Cholesky_solve(A, s, r, b, n)
		return
	end function
	\end{fortran}

	\pagebreak
	\appendixpage
	\appendix \section*{Código}
	\lstinputlisting[style=fortranstyle, gobble=0]{matrixlib.f95}
%	\begin{thebibliography}{10}
%		
%	\end{thebibliography}
\end{document}
